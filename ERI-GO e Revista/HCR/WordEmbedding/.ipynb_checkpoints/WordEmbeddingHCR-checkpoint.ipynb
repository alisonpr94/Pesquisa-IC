{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_predict, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Preprocessamento(object):\n",
    "    def __init__(self):\n",
    "        self.all_twitter_messages = None\n",
    "        self.polarity_tweets = None\n",
    "        self.tweets_stemming = None\n",
    "        self.palavras = []\n",
    "\n",
    "    def read_tweets_from_file(self, dataset):\n",
    "        self.all_twitter_messages = dataset['content'].values\n",
    "\n",
    "        return self.all_twitter_messages\n",
    "\n",
    "    def read_polarity_from_file(self, dataset):\n",
    "        self.polarity_tweets = dataset['sentiment'].values\n",
    "\n",
    "        return self.polarity_tweets\n",
    "\n",
    "    def clean_tweets(self, tweet):\n",
    "        tweet = re.sub('@(\\w{1,15})\\b', '', tweet)\n",
    "        tweet = tweet.replace(\"via \", \"\")\n",
    "        tweet = tweet.replace(\"RT \", \"\")\n",
    "        tweet = tweet.lower()\n",
    "\n",
    "        return tweet\n",
    "\n",
    "    def clean_url(self, tweet):\n",
    "        tweet = re.sub(r'(https|http)?://(\\w|\\.|/|\\?|=|&|%)*\\b', '', tweet, flags=re.MULTILINE)\n",
    "        tweet = tweet.replace(\"http\", \"\")\n",
    "        tweet = tweet.replace(\"htt\", \"\")\n",
    "\n",
    "        return tweet\n",
    "\n",
    "    def remove_stop_words(self, tweet):\n",
    "        english_stops = set(stopwords.words('english'))\n",
    "\n",
    "        words = [i for i in tweet.split() if not i in english_stops]\n",
    "\n",
    "        return (\" \".join(words))\n",
    "\n",
    "    def stemming_tweets(self, tweet):\n",
    "        ps = PorterStemmer()\n",
    "\n",
    "        self.tweets_stemming = ps.stem(tweet)\n",
    "\n",
    "        return self.tweets_stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv('hcr-train.csv')\n",
    "dataset_test = pd.read_csv('hcr-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet id</th>\n",
       "      <th>user id</th>\n",
       "      <th>username</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>target</th>\n",
       "      <th>annotator id</th>\n",
       "      <th>comment</th>\n",
       "      <th>dispute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10237553563</td>\n",
       "      <td>69128478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RT @angelsmomaw: #HCR is unwanted because it w...</td>\n",
       "      <td>negative</td>\n",
       "      <td>hcr</td>\n",
       "      <td>aluckhardt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10239984258</td>\n",
       "      <td>7713202</td>\n",
       "      <td>GOPLeader</td>\n",
       "      <td>RT @WMRepublicans President's Remarks Yesterda...</td>\n",
       "      <td>negative</td>\n",
       "      <td>hcr</td>\n",
       "      <td>aluckhardt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10240791063</td>\n",
       "      <td>34927577</td>\n",
       "      <td>cnsnews_com</td>\n",
       "      <td>RT @johnboehner: Pelosi on #HCR: ''We have to ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>dems</td>\n",
       "      <td>aluckhardt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10253203734,16930489,ExJon,\"RT @vermontaigne C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10255459398,15350894,LJSearles,\"RT @HealthRefo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tweet id   user id     username  \\\n",
       "0                                        10237553563  69128478          NaN   \n",
       "1                                        10239984258   7713202    GOPLeader   \n",
       "2                                        10240791063  34927577  cnsnews_com   \n",
       "3  10253203734,16930489,ExJon,\"RT @vermontaigne C...       NaN          NaN   \n",
       "4  10255459398,15350894,LJSearles,\"RT @HealthRefo...       NaN          NaN   \n",
       "\n",
       "                                             content  sentiment target  \\\n",
       "0  RT @angelsmomaw: #HCR is unwanted because it w...   negative    hcr   \n",
       "1  RT @WMRepublicans President's Remarks Yesterda...   negative    hcr   \n",
       "2  RT @johnboehner: Pelosi on #HCR: ''We have to ...   negative   dems   \n",
       "3                                                NaN        NaN    NaN   \n",
       "4                                                NaN        NaN    NaN   \n",
       "\n",
       "  annotator id comment dispute  \n",
       "0   aluckhardt     NaN     NaN  \n",
       "1   aluckhardt     NaN     NaN  \n",
       "2   aluckhardt     NaN     NaN  \n",
       "3          NaN     NaN     NaN  \n",
       "4          NaN     NaN     NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet id</th>\n",
       "      <th>user id</th>\n",
       "      <th>username</th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>target</th>\n",
       "      <th>annotator id</th>\n",
       "      <th>comment</th>\n",
       "      <th>dispute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10729879540</td>\n",
       "      <td>19500327.0</td>\n",
       "      <td>willmckinley</td>\n",
       "      <td>50% of FoxNews.com readers think #hcr won't pa...</td>\n",
       "      <td>negative</td>\n",
       "      <td>conservatives</td>\n",
       "      <td>acoyne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10740632762</td>\n",
       "      <td>33972168.0</td>\n",
       "      <td>FREETeaPartyArt</td>\n",
       "      <td>NEW #teaparty sign download ---- Taking back o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>conservatives</td>\n",
       "      <td>supadhyay</td>\n",
       "      <td>Updated after multiple students pointed out sl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10780349787,16082787,slackadjuster,RT @Marnus3...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10781009520</td>\n",
       "      <td>18407451.0</td>\n",
       "      <td>BrazenlyLiberal</td>\n",
       "      <td>RT @hippieprof: RT @loudhearted: RT @quaigee: ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>conservatives</td>\n",
       "      <td>acoyne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10727641557,16175061,kpangrace,I'm confident t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            tweet id     user id  \\\n",
       "0                                        10729879540  19500327.0   \n",
       "1                                        10740632762  33972168.0   \n",
       "2  10780349787,16082787,slackadjuster,RT @Marnus3...         NaN   \n",
       "3                                        10781009520  18407451.0   \n",
       "4  10727641557,16175061,kpangrace,I'm confident t...         NaN   \n",
       "\n",
       "          username                                            content  \\\n",
       "0     willmckinley  50% of FoxNews.com readers think #hcr won't pa...   \n",
       "1  FREETeaPartyArt  NEW #teaparty sign download ---- Taking back o...   \n",
       "2              NaN                                                NaN   \n",
       "3  BrazenlyLiberal  RT @hippieprof: RT @loudhearted: RT @quaigee: ...   \n",
       "4              NaN                                                NaN   \n",
       "\n",
       "   sentiment          target annotator id  \\\n",
       "0   negative   conservatives       acoyne   \n",
       "1   positive   conservatives    supadhyay   \n",
       "2        NaN             NaN          NaN   \n",
       "3   negative   conservatives       acoyne   \n",
       "4        NaN             NaN          NaN   \n",
       "\n",
       "                                             comment  dispute  \n",
       "0                                                NaN      NaN  \n",
       "1  Updated after multiple students pointed out sl...      NaN  \n",
       "2                                                NaN      NaN  \n",
       "3                                                NaN      NaN  \n",
       "4                                                NaN      NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RetiraPolaridade(object):\n",
    "    def __init__(self):\n",
    "        self.all_tweets = None\n",
    "        self.polaridade = None\n",
    "\n",
    "    def retira_polaridade(self, tweets, polaridade):\n",
    "        self.all_tweets = []\n",
    "        self.polaridade = []\n",
    "\n",
    "        for i in range(len(tweets)):\n",
    "            if polaridade[i] == 'positive' or polaridade[i] == 'negative' or polaridade[i] == 'neutral':\n",
    "                self.all_tweets.append(tweets[i])\n",
    "                self.polaridade.append(polaridade[i])\n",
    "\n",
    "        return self.all_tweets, self.polaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rp = RetiraPolaridade()\n",
    "pre = Preprocessamento()\n",
    "\n",
    "tweets_train = pre.read_tweets_from_file(dataset_train)\n",
    "polarity_train = pre.read_polarity_from_file(dataset_train)\n",
    "\n",
    "tweets_test = pre.read_tweets_from_file(dataset_test)\n",
    "polarity_test = pre.read_polarity_from_file(dataset_test)\n",
    "\n",
    "tweets_train, polarity_train = rp.retira_polaridade(tweets_train, polarity_train)\n",
    "tweets_test, polarity_test = rp.retira_polaridade(tweets_test, polarity_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(852, 327)\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets_train), len(tweets_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = len(tweets_test)\n",
    "\n",
    "''' Mesclando os dados de treino com os dados de teste '''\n",
    "\n",
    "all_tweets = []\n",
    "classes = []\n",
    "\n",
    "for tweet in tweets_train:\n",
    "    all_tweets.append(tweet)\n",
    "\n",
    "for tweet in tweets_test:\n",
    "    all_tweets.append(tweet)\n",
    "\n",
    "for classe in polarity_train:\n",
    "    classes.append(classe)\n",
    "\n",
    "for classe in polarity_test:\n",
    "    classes.append(classe)\n",
    "\n",
    "DATA_SIZE = len(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Preprocessamento dos dados de teste '''\n",
    "\n",
    "for i in range(len(all_tweets)):\n",
    "    all_tweets[i] = pre.clean_tweets(all_tweets[i])\n",
    "    all_tweets[i] = pre.clean_url(all_tweets[i])\n",
    "    all_tweets[i] = pre.remove_stop_words(all_tweets[i])\n",
    "    #all_tweets[i] = pre.stemming_tweets(all_tweets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, glove):\n",
    "        self.glove = glove\n",
    "        self.gloveweight = None\n",
    "        self.dim = len(glove.itervalues().next())\n",
    "\n",
    "    def fit(self, X):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.gloveweight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.glove[w] * self.gloveweight[w]\n",
    "                         for w in words if w in self.glove] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reading_glove(tweets, dim):\n",
    "    if dim == 25:\n",
    "        with open(\"glove.twitter.27B.25d.txt\", \"rb\") as lines:\n",
    "            glove = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "                for line in lines}\n",
    "\n",
    "    elif dim == 50:\n",
    "        with open(\"glove.twitter.27B.50d.txt\", \"rb\") as lines:\n",
    "            glove = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "                for line in lines}\n",
    "\n",
    "    elif dim == 100:\n",
    "        with open(\"glove.twitter.27B.100d.txt\", \"rb\") as lines:\n",
    "            glove = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "                for line in lines}\n",
    "\n",
    "    elif dim == 200:\n",
    "        with open(\"glove.twitter.27B.200d.txt\", \"rb\") as lines:\n",
    "            glove = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "                for line in lines}\n",
    "\n",
    "    else:\n",
    "        raise IOError(\"Dimensão do Word Embedding GloVe incorreta.\")\n",
    "\n",
    "    vec = TfidfEmbeddingVectorizer(glove)\n",
    "    vec.fit(tweets)\n",
    "    matrix = vec.transform(tweets)\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CriaLexicon(object):\n",
    "    def __init__(self):\n",
    "        self.matriz = []\n",
    "\n",
    "    def opinion_lexicon(self, lex_positivo, lex_negativo, all_tweets):\n",
    "        for tweet in all_tweets:\n",
    "            cont = [0.0 for i in range(3)]\n",
    "            contPos = 0\n",
    "            contNeg = 0\n",
    "\n",
    "            for word in word_tokenize(tweet.lower()):\n",
    "                if word in lex_positivo:\n",
    "                    contPos += 1\n",
    "\n",
    "                if word in lex_negativo:\n",
    "                    contNeg += 1\n",
    "\n",
    "            #print(contPos, contNeg)\n",
    "            if contPos > contNeg:\n",
    "                cont[0] = 1.0\n",
    "            elif contNeg > contPos:\n",
    "                cont[1] = 1.0\n",
    "            else:\n",
    "                cont[2] = 1.0\n",
    "\n",
    "            self.matriz.append(cont)\n",
    "\n",
    "        return self.matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pd.read_csv('opinion_lexicon/positive-words.csv')\n",
    "neg = pd.read_csv('opinion_lexicon/negative-words.csv')\n",
    "\n",
    "lex = CriaLexicon()\n",
    "\n",
    "pos = pos['pos']\n",
    "neg = neg['neg']\n",
    "\n",
    "matrix_lex = lex.opinion_lexicon(list(pos), list(neg), all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0]]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_lex[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criando modelo Bag-of-Words a partir de features do dataset\n",
    "vec = CountVectorizer(binary=True)\n",
    "vec.fit(all_tweets)\n",
    "matrix_bow = vec.transform(all_tweets).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1179, 4025)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1179, 25)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_embedding = reading_glove(all_tweets, 25)\n",
    "matrix_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1179, 4053)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = np.concatenate((matrix_embedding, matrix_bow, matrix_lex), axis=1)\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia...: 65.68\n",
      "Precision..: 63.49\n",
      "Recall.....: 60.29\n",
      "F1-Score...: 61.14\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.6190    0.5909    0.6047        66\n",
      "   negative     0.6912    0.8103    0.7460       116\n",
      "    neutral     0.5946    0.4074    0.4835        54\n",
      "\n",
      "avg / total     0.6489    0.6568    0.6464       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDIÇÃO COM MODELO WORD EMBEDDING DE 25 DIMENSÕES + DICIONÁRIO LÉXICO\n",
    "matrix_embedding = reading_glove(all_tweets, 25)\n",
    "\n",
    "matrix = np.concatenate((matrix_embedding, matrix_bow, matrix_lex), axis=1)\n",
    "\n",
    "size = ((TEST_SIZE * 100) / DATA_SIZE) / 100\n",
    "size = size * 0.01\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(matrix, classes, test_size=0.2)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "resultados = lr.predict(X_test)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acurácia...: %.2f\" %(metrics.accuracy_score(y_test,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(y_test,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(y_test,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(y_test,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(y_test,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia...: 68.22\n",
      "Precision..: 70.31\n",
      "Recall.....: 63.34\n",
      "F1-Score...: 65.34\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.6500    0.5821    0.6142        67\n",
      "   negative     0.6713    0.8276    0.7413       116\n",
      "    neutral     0.7879    0.4906    0.6047        53\n",
      "\n",
      "avg / total     0.6914    0.6822    0.6745       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDIÇÃO COM MODELO WORD EMBEDDING DE 50 DIMENSÕES + DICIONÁRIO LÉXICO\n",
    "matrix_embedding = reading_glove(all_tweets, 50)\n",
    "\n",
    "matrix = np.concatenate((matrix_embedding, matrix_bow, matrix_lex), axis=1)\n",
    "\n",
    "size = ((TEST_SIZE * 100) / DATA_SIZE) / 100\n",
    "size = size * 0.01\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(matrix, classes, test_size=0.2)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "resultados = lr.predict(X_test)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acurácia...: %.2f\" %(metrics.accuracy_score(y_test,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(y_test,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(y_test,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(y_test,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(y_test,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia...: 62.29\n",
      "Precision..: 58.92\n",
      "Recall.....: 55.56\n",
      "F1-Score...: 55.91\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.5556    0.5797    0.5674        69\n",
      "   negative     0.6765    0.7931    0.7302       116\n",
      "    neutral     0.5357    0.2941    0.3797        51\n",
      "\n",
      "avg / total     0.6107    0.6229    0.6068       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDIÇÃO COM MODELO WORD EMBEDDING DE 100 DIMENSÕES + DICIONÁRIO LÉXICO\n",
    "matrix_embedding = reading_glove(all_tweets, 100)\n",
    "\n",
    "matrix = np.concatenate((matrix_embedding, matrix_bow, matrix_lex), axis=1)\n",
    "\n",
    "size = ((TEST_SIZE * 100) / DATA_SIZE) / 100\n",
    "size = size * 0.01\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(matrix, classes, test_size=0.2)\n",
    "\n",
    "lr = LogisticRegression(C=2.0)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "resultados = lr.predict(X_test)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acurácia...: %.2f\" %(metrics.accuracy_score(y_test,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(y_test,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(y_test,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(y_test,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(y_test,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia...: 63.14\n",
      "Precision..: 61.11\n",
      "Recall.....: 57.59\n",
      "F1-Score...: 58.48\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.6949    0.5125    0.5899        80\n",
      "   negative     0.6383    0.7965    0.7087       113\n",
      "    neutral     0.5000    0.4186    0.4557        43\n",
      "\n",
      "avg / total     0.6323    0.6314    0.6223       236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDIÇÃO COM MODELO WORD EMBEDDING DE 200 DIMENSÕES + DICIONÁRIO LÉXICO\n",
    "matrix_embedding = reading_glove(all_tweets, 200)\n",
    "\n",
    "matrix = np.concatenate((matrix_embedding, matrix_lex, matrix_bow), axis=1)\n",
    "\n",
    "size = ((TEST_SIZE * 100) / DATA_SIZE) / 100\n",
    "size = size * 0.01\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(matrix, classes, test_size=0.2)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "resultados = lr.predict(X_test)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acurácia...: %.2f\" %(metrics.accuracy_score(y_test,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(y_test,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(y_test,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(y_test,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(y_test,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

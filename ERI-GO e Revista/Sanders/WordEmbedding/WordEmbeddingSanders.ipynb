{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_predict, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Preprocessamento(object):\n",
    "    def __init__(self):\n",
    "        self.all_twitter_messages = None\n",
    "        self.polarity_tweets = None\n",
    "        self.tweets_stemming = None\n",
    "        self.palavras = []\n",
    "\n",
    "    def read_tweets_from_file(self, dataset):\n",
    "        self.all_twitter_messages = dataset['text'].values\n",
    "\n",
    "        return self.all_twitter_messages\n",
    "\n",
    "    def read_polarity_from_file(self, dataset):\n",
    "        self.polarity_tweets = dataset['class'].values\n",
    "\n",
    "        return self.polarity_tweets\n",
    "\n",
    "    def clean_tweets(self, tweet):\n",
    "        tweet = re.sub('@(\\w{1,15})\\b', '', tweet)\n",
    "        tweet = tweet.replace(\"via \", \"\")\n",
    "        tweet = tweet.replace(\"RT \", \"\")\n",
    "        tweet = tweet.lower()\n",
    "\n",
    "        return tweet\n",
    "\n",
    "    def clean_url(self, tweet):\n",
    "        tweet = re.sub(r'(https|http)?://(\\w|\\.|/|\\?|=|&|%)*\\b', '', tweet, flags=re.MULTILINE)\n",
    "        tweet = tweet.replace(\"http\", \"\")\n",
    "        tweet = tweet.replace(\"htt\", \"\")\n",
    "\n",
    "        return tweet\n",
    "\n",
    "    def remove_stop_words(self, tweet):\n",
    "        english_stops = set(stopwords.words('english'))\n",
    "\n",
    "        words = [i for i in tweet.split() if not i in english_stops]\n",
    "\n",
    "        return (\" \".join(words))\n",
    "\n",
    "    def stemming_tweets(self, tweet):\n",
    "        ps = PorterStemmer()\n",
    "\n",
    "        self.tweets_stemming = ps.stem(tweet)\n",
    "\n",
    "        return self.tweets_stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>1,26418790706713E+017</th>\n",
       "      <th>2011-10-18 22:06:03</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>apple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>1,26417285559763E+017</td>\n",
       "      <td>2011-10-18 22:00:04</td>\n",
       "      <td>RT @Jewelz2611 @mashable @apple, iphones r 2 e...</td>\n",
       "      <td>negative</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>1,26416915664085E+017</td>\n",
       "      <td>2011-10-18 21:58:36</td>\n",
       "      <td>@mashable @apple, iphones r 2 expensive. Most ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>1,2641610921268E+017</td>\n",
       "      <td>2011-10-18 21:55:23</td>\n",
       "      <td>THiS IS WHAT WiLL KiLL APPLE http://t.co/72Jw4...</td>\n",
       "      <td>negative</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>1,26411162622497E+017</td>\n",
       "      <td>2011-10-18 21:35:44</td>\n",
       "      <td>@apple why my tunes no go on my iPhone? iPhone...</td>\n",
       "      <td>negative</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>1,26410591949697E+017</td>\n",
       "      <td>2011-10-18 21:33:28</td>\n",
       "      <td>@apple needs to hurry up and release #iTunesMatch</td>\n",
       "      <td>negative</td>\n",
       "      <td>apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   10  1,26418790706713E+017  2011-10-18 22:06:03  \\\n",
       "0  12  1,26417285559763E+017  2011-10-18 22:00:04   \n",
       "1  13  1,26416915664085E+017  2011-10-18 21:58:36   \n",
       "2  14   1,2641610921268E+017  2011-10-18 21:55:23   \n",
       "3  20  1,26411162622497E+017  2011-10-18 21:35:44   \n",
       "4  21  1,26410591949697E+017  2011-10-18 21:33:28   \n",
       "\n",
       "                                                text     class  apple  \n",
       "0  RT @Jewelz2611 @mashable @apple, iphones r 2 e...  negative  apple  \n",
       "1  @mashable @apple, iphones r 2 expensive. Most ...  negative  apple  \n",
       "2  THiS IS WHAT WiLL KiLL APPLE http://t.co/72Jw4...  negative  apple  \n",
       "3  @apple why my tunes no go on my iPhone? iPhone...  negative  apple  \n",
       "4  @apple needs to hurry up and release #iTunesMatch  negative  apple  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('sentiment.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre = Preprocessamento()\n",
    "\n",
    "tweets = pre.read_tweets_from_file(dataset)\n",
    "classes = pre.read_polarity_from_file(dataset)\n",
    "\n",
    "for i in range(len(tweets)):\n",
    "    tweets[i] = pre.clean_tweets(tweets[i])\n",
    "    tweets[i] = pre.clean_url(tweets[i])\n",
    "    tweets[i] = pre.remove_stop_words(tweets[i])\n",
    "    #tweets[i] = pre.stemming_tweets(tweets[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, glove):\n",
    "        self.glove = glove\n",
    "        self.gloveweight = None\n",
    "        self.dim = len(glove.itervalues().next())\n",
    "\n",
    "    def fit(self, X):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.gloveweight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.glove[w] * self.gloveweight[w]\n",
    "                         for w in words if w in self.glove] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reading_glove(tweets, dim):\n",
    "    if dim == 25:\n",
    "        with open(\"glove.twitter.27B.25d.txt\", \"rb\") as lines:\n",
    "            glove = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "                for line in lines}\n",
    "\n",
    "    elif dim == 50:\n",
    "        with open(\"glove.twitter.27B.50d.txt\", \"rb\") as lines:\n",
    "            glove = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "                for line in lines}\n",
    "\n",
    "    elif dim == 100:\n",
    "        with open(\"glove.twitter.27B.100d.txt\", \"rb\") as lines:\n",
    "            glove = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "                for line in lines}\n",
    "\n",
    "    elif dim == 200:\n",
    "        with open(\"glove.twitter.27B.200d.txt\", \"rb\") as lines:\n",
    "            glove = {line.split()[0]: np.array(map(float, line.split()[1:]))\n",
    "                for line in lines}\n",
    "\n",
    "    else:\n",
    "        raise IOError(\"Dimens√£o do Word Embedding GloVe incorreta.\")\n",
    "\n",
    "    vec = TfidfEmbeddingVectorizer(glove)\n",
    "    vec.fit(tweets)\n",
    "    matrix = vec.transform(tweets)\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_embedding = reading_glove(tweets, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.74158081, -0.09020527, -0.23958878, ...,  0.41816403,\n",
       "         0.51970329,  0.54564075],\n",
       "       [ 0.75250516, -0.10413246, -0.27322124, ...,  0.41866373,\n",
       "         0.52397909,  0.54214831],\n",
       "       [ 0.59369938,  0.1585609 ,  0.0125712 , ...,  0.38925703,\n",
       "         0.3441153 ,  0.1891449 ],\n",
       "       ...,\n",
       "       [ 0.80997711,  0.06203335, -0.32969777, ...,  0.18935582,\n",
       "         0.4486442 ,  0.41699773],\n",
       "       [ 0.63714674,  0.27908308, -0.53452825, ...,  0.42038817,\n",
       "         0.36260061,  0.45314085],\n",
       "       [ 0.81551927,  0.03060585, -0.21039117, ...,  0.40729726,\n",
       "         0.44257708,  0.3831267 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Criando modelo Bag-of-Words a partir de features do dataset\n",
    "vec = CountVectorizer(binary=True)\n",
    "vec.fit(tweets)\n",
    "matrix_bow = vec.transform(tweets).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 66.91\n",
      "Precision..: 43.28\n",
      "Recall.....: 34.26\n",
      "F1-Score...: 29.36\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.2778    0.0088    0.0170       570\n",
      "   negative     0.3438    0.0337    0.0614       653\n",
      "    neutral     0.6767    0.9852    0.8023      2503\n",
      "\n",
      "avg / total     0.5573    0.6691    0.5523      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO WORD EMBEDDING DE 25 DIMENS√ïES\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix_embedding, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 67.39\n",
      "Precision..: 50.22\n",
      "Recall.....: 35.36\n",
      "F1-Score...: 31.52\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.3846    0.0263    0.0493       570\n",
      "   negative     0.4400    0.0505    0.0907       653\n",
      "    neutral     0.6819    0.9840    0.8056      2503\n",
      "\n",
      "avg / total     0.5940    0.6739    0.5646      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO WORD EMBEDDING DE 50 DIMENS√ïES\n",
    "matrix_embedding = reading_glove(tweets, 50)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix_embedding, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 67.55\n",
      "Precision..: 52.13\n",
      "Recall.....: 36.19\n",
      "F1-Score...: 33.15\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.4130    0.0333    0.0617       570\n",
      "   negative     0.4660    0.0735    0.1270       653\n",
      "    neutral     0.6849    0.9788    0.8059      2503\n",
      "\n",
      "avg / total     0.6050    0.6755    0.5731      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO WORD EMBEDDING DE 100 DIMENS√ïES\n",
    "matrix_embedding = reading_glove(tweets, 100)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix_embedding, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 67.79\n",
      "Precision..: 54.27\n",
      "Recall.....: 37.07\n",
      "F1-Score...: 34.73\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.4255    0.0351    0.0648       570\n",
      "   negative     0.5154    0.1026    0.1711       653\n",
      "    neutral     0.6872    0.9744    0.8060      2503\n",
      "\n",
      "avg / total     0.6171    0.6779    0.5814      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO WORD EMBEDDING DE 200 DIMENS√ïES\n",
    "matrix_embedding = reading_glove(tweets, 200)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix_embedding, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 77.62\n",
      "Precision..: 74.23\n",
      "Recall.....: 60.76\n",
      "F1-Score...: 65.07\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.6636    0.3807    0.4838       570\n",
      "   negative     0.7746    0.5054    0.6117       653\n",
      "    neutral     0.7888    0.9369    0.8565      2503\n",
      "\n",
      "avg / total     0.7671    0.7762    0.7566      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO BAG-OF-WORDS\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix_bow, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lex_positivo = pd.read_csv('opinion_lexicon/positive-words.csv')\n",
    "lex_negativo = pd.read_csv('opinion_lexicon/negative-words.csv')\n",
    "lex_positivo = lex_positivo['pos']\n",
    "lex_negativo = lex_negativo['neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           a+\n",
       "1       abound\n",
       "2      abounds\n",
       "3    abundance\n",
       "4     abundant\n",
       "Name: pos, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex_positivo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2-faced\n",
       "1       2-faces\n",
       "2      abnormal\n",
       "3       abolish\n",
       "4    abominable\n",
       "Name: neg, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex_negativo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6789"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lex_positivo)+len(lex_negativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 77.43\n",
      "Precision..: 73.51\n",
      "Recall.....: 61.21\n",
      "F1-Score...: 65.25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.6737    0.3912    0.4950       570\n",
      "   negative     0.7407    0.5161    0.6083       653\n",
      "    neutral     0.7908    0.9289    0.8543      2503\n",
      "\n",
      "avg / total     0.7641    0.7743    0.7562      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO BAG-OF-WORDS + WORD EMBEDDING DE 25 DIMENS√ïES - UNIGRAM\n",
    "matrix_embedding = reading_glove(tweets, 25)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "matrix = np.concatenate((matrix_bow, matrix_embedding), axis=1)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 76.76\n",
      "Precision..: 72.09\n",
      "Recall.....: 59.95\n",
      "F1-Score...: 63.85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.6398    0.3614    0.4619       570\n",
      "   negative     0.7367    0.5100    0.6027       653\n",
      "    neutral     0.7862    0.9273    0.8510      2503\n",
      "\n",
      "avg / total     0.7552    0.7676    0.7479      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO BAG-OF-WORDS + WORD EMBEDDING DE 50 DIMENS√ïES - UNIGRAM\n",
    "matrix_embedding = reading_glove(tweets, 50)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "matrix = np.concatenate((matrix_bow, matrix_embedding), axis=1)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 77.48\n",
      "Precision..: 73.78\n",
      "Recall.....: 60.87\n",
      "F1-Score...: 65.04\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.6860    0.3947    0.5011       570\n",
      "   negative     0.7370    0.4977    0.5941       653\n",
      "    neutral     0.7903    0.9337    0.8560      2503\n",
      "\n",
      "avg / total     0.7650    0.7748    0.7558      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO BAG-OF-WORDS + WORD EMBEDDING DE 100 DIMENS√ïES - UNIGRAM\n",
    "matrix_embedding = reading_glove(tweets, 100)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "matrix = np.concatenate((matrix_bow, matrix_embedding), axis=1)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 77.62\n",
      "Precision..: 73.94\n",
      "Recall.....: 61.66\n",
      "F1-Score...: 65.79\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.6705    0.4140    0.5119       570\n",
      "   negative     0.7557    0.5069    0.6068       653\n",
      "    neutral     0.7919    0.9289    0.8549      2503\n",
      "\n",
      "avg / total     0.7670    0.7762    0.7590      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO BAG-OF-WORDS + WORD EMBEDDING DE 200 DIMENS√ïES - UNIGRAM\n",
    "matrix_embedding = reading_glove(tweets, 200)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "matrix = np.concatenate((matrix_bow, matrix_embedding), axis=1)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Gram(object):\n",
    "    def __init__(self):\n",
    "        self.bigram = None\n",
    "        self.trigram = None\n",
    "        \n",
    "    def create_bigram(self, tweet):\n",
    "        self.bigram = []\n",
    "        \n",
    "        for i in range(len(tweet)-1):\n",
    "            b_gram = tweet[i] + \"_\" + tweet[i+1]\n",
    "            self.bigram.append(b_gram)\n",
    "            \n",
    "        return (\" \".join(self.bigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gram = Gram()\n",
    "\n",
    "tweets_bigram = []\n",
    "\n",
    "for i in range(len(tweets)):\n",
    "    tweets_bigram.append(gram.create_bigram(tweets[i].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3726"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_uni_big = tweets + tweets_bigram\n",
    "tweets_uni_big[0]\n",
    "len(tweets_uni_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_vectorizer(tweets):\n",
    "    # Criando modelo Bag-of-Words a partir de features do dataset\n",
    "    cv = CountVectorizer(binary=True)\n",
    "    cv.fit(tweets)\n",
    "    matrix = cv.transform(tweets).toarray()\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_bow_big = count_vectorizer(tweets_bigram)\n",
    "matrix_bow_uni_big = count_vectorizer(tweets_uni_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 75.17\n",
      "Precision..: 74.40\n",
      "Recall.....: 53.88\n",
      "F1-Score...: 58.49\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.7292    0.3070    0.4321       570\n",
      "   negative     0.7492    0.3522    0.4792       653\n",
      "    neutral     0.7537    0.9573    0.8434      2503\n",
      "\n",
      "avg / total     0.7492    0.7517    0.7166      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO BAG-OF-WORDS - BIGRAM\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix_bow_big, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 77.59\n",
      "Precision..: 75.26\n",
      "Recall.....: 60.37\n",
      "F1-Score...: 64.93\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.7115    0.3807    0.4960       570\n",
      "   negative     0.7619    0.4900    0.5965       653\n",
      "    neutral     0.7844    0.9405    0.8554      2503\n",
      "\n",
      "avg / total     0.7693    0.7759    0.7550      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO BAG-OF-WORDS - UNIGRAM + BIGRAM\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix_bow_uni_big, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 77.59\n",
      "Precision..: 75.44\n",
      "Recall.....: 60.22\n",
      "F1-Score...: 64.82\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.7176    0.3789    0.4960       570\n",
      "   negative     0.7620    0.4855    0.5931       653\n",
      "    neutral     0.7836    0.9421    0.8556      2503\n",
      "\n",
      "avg / total     0.7698    0.7759    0.7546      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO BAG-OF-WORDS + WORD EMBEDDING DE 25 DIMENS√ïES - UNIGRAM + BIGRAM\n",
    "matrix_embedding = reading_glove(tweets, 25)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "matrix = np.concatenate((matrix_bow_uni_big, matrix_embedding), axis=1)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 78.02\n",
      "Precision..: 75.88\n",
      "Recall.....: 61.20\n",
      "F1-Score...: 65.82\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.7169    0.4088    0.5207       570\n",
      "   negative     0.7713    0.4855    0.5959       653\n",
      "    neutral     0.7883    0.9417    0.8582      2503\n",
      "\n",
      "avg / total     0.7744    0.7802    0.7606      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO BAG-OF-WORDS + WORD EMBEDDING DE 50 DIMENS√ïES - UNIGRAM + BIGRAM\n",
    "matrix_embedding = reading_glove(tweets, 50)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "matrix = np.concatenate((matrix_bow_uni_big, matrix_embedding), axis=1)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 77.94\n",
      "Precision..: 75.74\n",
      "Recall.....: 60.79\n",
      "F1-Score...: 65.43\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.7000    0.3930    0.5034       570\n",
      "   negative     0.7852    0.4870    0.6011       653\n",
      "    neutral     0.7871    0.9437    0.8583      2503\n",
      "\n",
      "avg / total     0.7734    0.7794    0.7589      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO BAG-OF-WORDS + WORD EMBEDDING DE 100 DIMENS√ïES - UNIGRAM + BIGRAM\n",
    "matrix_embedding = reading_glove(tweets, 100)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "matrix = np.concatenate((matrix_bow_uni_big, matrix_embedding), axis=1)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 78.34\n",
      "Precision..: 76.16\n",
      "Recall.....: 61.91\n",
      "F1-Score...: 66.50\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.7333    0.4246    0.5378       570\n",
      "   negative     0.7589    0.4916    0.5967       653\n",
      "    neutral     0.7925    0.9413    0.8605      2503\n",
      "\n",
      "avg / total     0.7775    0.7834    0.7649      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO BAG-OF-WORDS + WORD EMBEDDING DE 200 DIMENS√ïES - UNIGRAM + BIGRAM\n",
    "matrix_embedding = reading_glove(tweets, 200)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "matrix = np.concatenate((matrix_bow_uni_big, matrix_embedding), axis=1)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.00000 0.00000 1.00000',\n",
       " '0.00000 0.00000 1.00000',\n",
       " '0.00000 1.00000 0.00000',\n",
       " '0.00000 1.00000 0.00000',\n",
       " '0.00000 0.00000 1.00000']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lex_file = open('lex.txt', 'r')\n",
    "lexicon = lex_file.read().splitlines()\n",
    "lex_file.close()\n",
    "lexicon[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = lexicon[0].split()\n",
    "lista = map(float, lista)\n",
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_lex = []\n",
    "\n",
    "for i in range(len(lexicon)):\n",
    "    vec = lexicon[i].split()\n",
    "    vec = map(float, vec)\n",
    "    matrix_lex.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0, 1.0],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 1.0]]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_lex[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 78.77\n",
      "Precision..: 73.69\n",
      "Recall.....: 65.66\n",
      "F1-Score...: 68.81\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.6464    0.4842    0.5537       570\n",
      "   negative     0.7480    0.5727    0.6487       653\n",
      "    neutral     0.8164    0.9129    0.8619      2503\n",
      "\n",
      "avg / total     0.7784    0.7877    0.7774      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO BAG-OF-WORDS + DICION√ÅRIO L√âXICO - UNIGRAM + BIGRAM\n",
    "lr = LogisticRegression(C=10.0)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "matrix = np.concatenate((matrix_bow_uni_big, matrix_lex), axis=1)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 78.56\n",
      "Precision..: 74.53\n",
      "Recall.....: 63.36\n",
      "F1-Score...: 67.25\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.6893    0.4281    0.5281       570\n",
      "   negative     0.7421    0.5421    0.6265       653\n",
      "    neutral     0.8045    0.9305    0.8629      2503\n",
      "\n",
      "avg / total     0.7759    0.7856    0.7703      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO BAG-OF-WORDS + L√âXICO + WORD EMBEDDING DE 25 DIMENS√ïES - UNIGRAM + BIGRAM\n",
    "matrix_embedding = reading_glove(tweets, 25)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "matrix = np.concatenate((matrix_bow_uni_big, matrix_embedding, matrix_lex), axis=1)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 78.77\n",
      "Precision..: 75.17\n",
      "Recall.....: 63.68\n",
      "F1-Score...: 67.66\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.7003    0.4263    0.5300       570\n",
      "   negative     0.7505    0.5528    0.6367       653\n",
      "    neutral     0.8043    0.9313    0.8632      2503\n",
      "\n",
      "avg / total     0.7790    0.7877    0.7725      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO BAG-OF-WORDS + L√âXICO + WORD EMBEDDING DE 50 DIMENS√ïES - UNIGRAM + BIGRAM\n",
    "matrix_embedding = reading_glove(tweets, 50)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "matrix = np.concatenate((matrix_bow_uni_big, matrix_embedding, matrix_lex), axis=1)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 79.15\n",
      "Precision..: 75.83\n",
      "Recall.....: 64.15\n",
      "F1-Score...: 68.26\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.6975    0.4491    0.5464       570\n",
      "   negative     0.7707    0.5406    0.6355       653\n",
      "    neutral     0.8066    0.9349    0.8660      2503\n",
      "\n",
      "avg / total     0.7836    0.7915    0.7767      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO BAG-OF-WORDS + L√âXICO + WORD EMBEDDING DE 100 DIMENS√ïES - UNIGRAM + BIGRAM\n",
    "matrix_embedding = reading_glove(tweets, 100)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "matrix = np.concatenate((matrix_bow_uni_big, matrix_embedding, matrix_lex), axis=1)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acur√°cia...: 79.36\n",
      "Precision..: 75.82\n",
      "Recall.....: 64.89\n",
      "F1-Score...: 68.85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   positive     0.6919    0.4649    0.5561       570\n",
      "   negative     0.7720    0.5498    0.6422       653\n",
      "    neutral     0.8106    0.9321    0.8671      2503\n",
      "\n",
      "avg / total     0.7857    0.7936    0.7801      3726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PREDI√á√ÉO COM MODELO BAG-OF-WORDS + L√âXICO + WORD EMBEDDING DE 200 DIMENS√ïES - UNIGRAM + BIGRAM\n",
    "matrix_embedding = reading_glove(tweets, 200)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "matrix = np.concatenate((matrix_bow_uni_big, matrix_embedding, matrix_lex), axis=1)\n",
    "\n",
    "resultados = cross_val_predict(lr, matrix, classes, cv = kfold)\n",
    "\n",
    "sentimento = ['positive', 'negative', 'neutral']\n",
    "\n",
    "print(\"Acur√°cia...: %.2f\" %(metrics.accuracy_score(classes,resultados) * 100))\n",
    "print(\"Precision..: %.2f\" %(metrics.precision_score(classes,resultados,average='macro') * 100))\n",
    "print(\"Recall.....: %.2f\" %(metrics.recall_score(classes,resultados, average='macro') * 100))\n",
    "print(\"F1-Score...: %.2f\" %(metrics.f1_score(classes,resultados, average='macro') * 100))\n",
    "#print()\n",
    "print(metrics.classification_report(classes,resultados,sentimento,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lex_positivo = list(lex_positivo)\n",
    "lex_negativo = list(lex_negativo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv2 = CountVectorizer(vocabulary=set(lex_positivo+lex_negativo), binary=True)\n",
    "cv2.fit(tweets_uni_big)\n",
    "bow_lex = cv2.transform(tweets_uni_big).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3726, 6786)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_lex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acuracia = [78.56, 78.77, 79.15, 79.36]\n",
    "precisao = [74.53, 75.17, 75.83, 75.82]\n",
    "recall = [63.36, 63.68, 64.15, 64.89]\n",
    "f1 = [67.25, 67.66, 68.26, 68.85]\n",
    "dimensoes = [25, 50, 100, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAEQCAYAAAD2/KAsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiQBCSGEUIQkICGEEIr4P/oiP8Xfr3WEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa640659cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_groups = 4\n",
    "\n",
    "means_men = (20, 35, 30, 35)\n",
    "std_men = (2, 3, 4, 1)\n",
    "\n",
    "means_women = (25, 32, 34, 20)\n",
    "std_women = (3, 5, 2, 3)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "\n",
    "opacity = 0.4\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "rects1 = plt.bar(index, means_men, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='b',\n",
    "                 yerr=std_men,\n",
    "                 error_kw=error_config,\n",
    "                 label='Acuracia')\n",
    "\n",
    "rects2 = plt.bar(index + bar_width, means_women, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='r',\n",
    "                 yerr=std_women,\n",
    "                 error_kw=error_config,\n",
    "                 label='Precision')\n",
    "\n",
    "rects3 = plt.bar(index + bar_width, means_women, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='r',\n",
    "                 yerr=std_women,\n",
    "                 error_kw=error_config,\n",
    "                 label='Recall')\n",
    "\n",
    "rects4 = plt.bar(index + bar_width, means_women, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color='r',\n",
    "                 yerr=std_women,\n",
    "                 error_kw=error_config,\n",
    "                 label='F1')\n",
    "\n",
    "plt.xlabel('Dim')\n",
    "plt.ylabel('(%)')\n",
    "plt.title('Scores by group and gender')\n",
    "plt.xticks(index + bar_width / 2, ('25', '50', '100', '200', 'E'))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
